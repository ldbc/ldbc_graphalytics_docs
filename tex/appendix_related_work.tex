\chapter{Related work}
\label{chap:related-work}



\begin{table*}[!ht]
	\centering
	\caption[Overview of related work]{Overview of related work. {\small (Acronyms: 
			\emph{Reference type}: {\bf S}, study; {\bf B}, benchmark. \emph{Target system, structure}: {\bf D}, distributed system; {\bf P}, parallel system; {\bf MC},  single-node multi-core system; {\bf GPU}, using GPUs. 
			\emph{Input}: {\bf 0}, no parameters; {\bf S}, parameters define scale; {\bf E}, parameters define edge properties; {\bf +}, parameters define other graph properties, e.g., clustering coefficient.
			\emph{Datasets/Algorithms}: {\bf Rnd}, reason for selection not explained; {\bf Exp}, selection guided by expertise; {\bf 1-stage}, data-driven selection; {\bf 2-stage}, 2-stage data- and expertise-driven process.
			\emph{Scalability tests}: {\bf W}, weak; {\bf S}, strong; {\bf V}, vertical; {\bf H}, horizontal.)}}
	\label{tab:SummaryOfRelatedWorkAcronyms}
	\resizebox{\textwidth}{!}{
		\input{tables/related_benchmarks-studies__vldb-summary.tex}
	}
	
\end{table*}


\autoref{tab:SummaryOfRelatedWorkAcronyms}, which is reproduced from~\cite{DBLP:journals/pvldb/IosupHNHPMCCSATXNB16}, summarizes and compares Graphalytics with previous studies and benchmarks for graph analysis systems. R1--R5 are the requirements formulated in \autoref{sec:requirements}. 
As the table indicates, there is no alternative to Graphalytics in covering requirements R1--R4. We also could not find evidence of requirement R5 being covered by other systems than LDBC.
% this is too gung-ho
% In summary, our Graphalytics proposes a judicious selection process for its workload selection, includes a tractable yet diverse baseline process, is designed to test key characteristics of large-scale graph-processing systems such as scalability and robustness, has comprehensive open-source tools for every step in the benchmarking process, includes a renewal process that promises longevity, and has the support of two benchmarking organizations (LDBC, but also SPEC). None of the alternatives we survey here can match these features; 
While there have been a few related \emph{benchmark proposals} (marked ``B''), these either do not {\em focus} on graph analysis, or are much narrower in scope (e.g., only BFS for Graph500).
There have been comparable \emph{studies} (marked ``S'') but these have not attempted to define---let alone maintain---a benchmark, its specification, software, testing tools and practices, or results.
Graphalytics is not only industry-backed but also has industrial strength, through its detailed execution process, its metrics that characterize robustness in addition to scalability, and a renewal process that promises longevity.
Graphalytics is being proposed to SPEC as well, and BigBench~\cite{DBLP:conf/sigmod/GhazalRHRPCJ13,DBLP:conf/sigmod/RablFDJG15} explicitly refers to Graphalytics as its option for future benchmarking of graph analysis platforms. 


Previous studies typically tested the open-source platforms Giraph~\cite{DBLP:books/sp/SOAK2016}, GraphX~\cite{DBLP:conf/sigmod/XinGFS13}, and 
PowerGraph~\cite{DBLP:conf/osdi/GonzalezLGBG12}, but our contribution here is that vendors (Oracle, Intel, IBM) in our evaluation have themselves tuned and tested their implementations for PGX~\cite{DBLP:conf/sc/HongDMLVC15}, GraphMat~\cite{DBLP:journals/pvldb/SundaramSPDAV0D15} and OpenG~\cite{DBLP:conf/sc/NaiXTKL15}. We are aware that the database community has started to realize that with some enhancements, RDBMS technology could also be a contender in this area~\cite{DBLP:conf/cidr/FanRP15,DBLP:journals/pvldb/JindalR0MDS14}, and we hope that such systems will soon get tested with Graphalytics. 

Graphalytics complements the many existing efforts focusing on graph databases, such as 
LinkBench~\cite{DBLP:conf/sigmod/ArmstrongPBC13}, 
XGDBench~\cite{DBLP:journals/ase/DayarathnaS14}, and 
LDBC SNB~\cite{DBLP:conf/sigmod/ErlingALCGPPB15,DBLP:conf/grades/SzarnyasPAMPKEB18};  
efforts focusing on RDF graph processing, such as 
LUBM~\cite{DBLP:journals/ws/GuoPH05},
the Berlin {SPARQL} Benchmark~\cite{DBLP:journals/ijswis/BizerS09},
SP\textsuperscript{2}Bench~\cite{DBLP:conf/icde/SchmidtHLP09},
and WatDiv~\cite{DBLP:conf/semweb/AlucHOD14} (targeting also graph databases);
and community efforts such as the TPC benchmarks.
Whereas all these prior efforts are interactive database query benchmarks, Graphalytics focuses on algorithmic graph analysis and on different platforms which are not necessarily database systems, whose distributed and highly parallel aspects lead to different design trade-offs.

The GAP Benchmark Suite~\cite{DBLP:journals/corr/BeamerAP15} targets six graph kernels: BFS, SSSP, PR, WCC, triangle count, and betweenness centrality. The first four are present in Graphalytics, while the \emph{triangle count} kernel shares many challenges with the LCC algorithm. (\emph{Betweenness centrality} was also considered for Graphalytics but it necessitates using approximation methods for large graphs, therefore automated validation of results is not possible.)
